\section{Semantic Analysis}

Often, a programming language is not just defined by its grammar
since the grammar cannot specify how programs should behave.
Therefore, a programming language's behavior is often defined by a so-called \emph{semantic specification}.
Unlike the grammar, the semantic specification does not specify the language's syntax.
Instead, this  specification often mandates how a program should behave.
Common rules include \emph{data types} and \emph{integer overflow behavior}.
Another example of a semantic rule is that a variable has to be defined before it is used.
Defining the semantic rules of a programming language is often a demanding task
since not all requirements are clear from the beginning.
Because the semantic rules of a programming language can not be defined formally,
a language designer often writes their specification in a natural language, meaning Chomsky type 0.
However, due to the specification being written in a natural language, the specification can sometimes be ambiguous.
Therefore, a well-written semantic specification should avoid ambiguity as much as possible.
Furthermore, this specification is often written in English
due to it being well-adopted language across several academic fields like computer science.
Since those rules define when a program is valid, they have to be checked and enforced before program compilation can start.

Because rush shares its semantic rules across all backends,
it would be cumbersome to implement semantic validation in each
backend individually. Therefore, it is rational to implement a separate
compilation step which is responsible for validating the source program's
semantics. Among other checks, the so-called \emph{semantic analyzer}\footnote{Later referred to as \enquote{analyzer}} validates types
and variable references whilst performing type annotations. The last aspect is
of particular importance since all compiler backends rely on type information at
compile time. However, in order to obtain type information, the abstract syntax
tree of the source program must be traversed, performing numerous other checks
during the process. The semantic analyzer behaves exactly like this. In order to
preserve a clear boundary between the individual compilation steps, the parser
only validates the program's syntax without performing further validation.
Therefore, the analyzer traverses the abstract syntax tree previously generated
by the parser.

In order to highlight why type information is often required at compile time, we
will consider following code example. The listing \ref{lst:analyzer-test} displays a basic rush program
calculating the sum of two integer values.
The program then uses this sum as its exit-code.
In this example, the desired exit-code of the program is five.

\TSListing[caption={A rush Program Which Adds Two Integers}, label={lst:analyzer-test}, float=H]{semantic_analysis_simple.rush}

In this example, the semantic analyzer will first check if the program contains
a \texttt{main} function. If this is not the case, the analyzer rejects the program
because it violates rush's semantic specification. Just like C or Rust, rush
requires that every program must contain exactly one \texttt{main} function. If a
programming language requires a \texttt{main} function, most top-level statements can be
completely forbidden, allowing more elegant code imports between different
source files. Furthermore, a \texttt{main} function clearly indicates the program's
start of execution, thus decreasing ambiguity. Therefore, the analyzer checks that
the \texttt{main} function takes no parameters and returns no value. However, in this
example, there is a valid \texttt{main} function. Now, the analyzer traverses the
function body of the \texttt{main} function. Since \texttt{let} statements are used to declare
new variables, the analyzer will add the variables \texttt{two} and \texttt{three} to its
current scope. However, unlike an interpreter, the analyzer does not insert the
variable's value into its scope. Instead of the concrete value, the analyzer
only considers the types of expressions. Therefore, in this example, the
analyzer remembers that the variables \texttt{two} and \texttt{three} store integer values.
This information will become much more useful when we consider line 4. Here, the
analyzer checks that the identifiers \texttt{two} and \texttt{three} refer to valid variables.
Just like most other programming languages, rush does not allow the addition
of two boolean values for example. Therefore, the analyzer checks that the operands
of the \texttt{+} operator have the same type and that this type is valid in additions.
Because this validation requires information about types, the analyzer accesses
its scope when looking up the identifiers \texttt{two} and \texttt{three}. Since those names
were previously mapped to the \texttt{int} type, the analyzer is now aware of the
operand types and can check their validity. In this case, calculating the
sum of two integers is legal and results in another integer value. Since rush's
semantic specification states that the \texttt{exit} function requires exactly one
integer parameter, the analyzer has to check that it is called correctly.
Furthermore, the analyzer validates all function calls and declarations, not
just the ones of builtin functions. Since the result of the addition is also an
integer, the analyzer accepts this program since both its syntax and semantics
are valid.

As indicated previously, most compilers require type information whilst
generating target code. For simplicity, we will consider a fictional compiler
which can compile both integer and float additions. However, the fictional
target machine requires different instructions for addition depending on the
type of the operands. For instance, integer addition uses the \texttt{intadd} instruction
while float addition uses the \texttt{floatadd} instruction. Here, type ambiguity would
cause difficulties. If there was no semantic analysis step, the compiler would
have to implement its own way of determining the types of the operands at
compile time. However, determining these types requires a complete
tree-traversal of the operand expressions. Due to the recursive design of the
abstract syntax tree, implementing this tree-traversal would require a
significant amount of source code in the compiler. However, the implementation
of this algorithm would be nearly identical accross all of rush's compiler
backends. Therefore, implementing type determination in each backend
individually would enlarge the compiler source code, thus making it harder to
understand. Since code duplication is considered inelegant, outsourcing this
algorithm into a separate component is likely the best option. As a result of
this, the semantic analyzer implements such a tree-traversal algorithm for
determining the types of subtrees. Because of the previously mentioned reasons,
rush's semantic analyzer also annotates the abstract syntax tree with type
information so that it is usable for later steps of compilation.

%- Main function: OK
%- Let statements
%- Variable references
%- Type compatibility
%- Exit uses int

Before examining how the analyzer's implementation behaves in the example from above,
we should first consider the attributes which play a vital role in the analyzer.

\TSListing[first line=12, last line=26, caption={Attributes of the \texttt{analyzer} struct}, label={lst:analyzer_attr}, float=H]{rush/crates/rush-analyzer/src/analyzer.rs}

Listing \ref{lst:analyzer_attr} displays the struct fields of the semantic analyzer.
The field \texttt{functions} in line 13 maps a function name to the function's signature.
Therefore, if a function is called later in the program, the analyzer checks if the function exists and can compare if the arguments match the declared parameters.
The \texttt{scopes} field in line 16 is responsible for managing variables.
In rush, blocks using braces (\texttt{\{\}}) create new scopes.
If the analyzer enters such a block, a new scope is pushed onto the \texttt{scopes} stack.
Each scope maps a variable identifier to some variable-specific data.
For instance, the analyzer keeps track of variable types, whether variables are used later, if they are mutated, and where it was declared.
By saving this much information about each declared variable, the analyzer can produce very helpful and accurate error messages and warnings.
Such an error message is displayed in listing \ref{lst:analyer_imutable_err}.

\AnsiListing[caption={Output When Compiling An Invalid rush Program}, float=h, label={lst:analyer_imutable_err}]{non_mut_variable_error.txt}

Furthermore, the \texttt{loop\_count} field is used to validate the uses of the \texttt{break} and \texttt{continue} keywords.
Because these statements are only valid inside loop bodies, the value of \texttt{loop\_count} must be $> 0$ when such a statement is used.
This counter is incremented as soon as the analyzer begins traversal of a loop body.
After the analyzer has traversed the loop's body, the counter is decremented again.
Due to this design, nested loops do not cause issues while the validity of the above statements can be guaranteed.

In order to obtain a better understanding of how the analyzer works, we will now
consider parts of its implementation and how they behave when analyzing the
example from above.

First, all functions are traversed and analyzed.
Because a \texttt{main} function is mandatory in every rush program,
the analyzer simply checks that the \texttt{functions} map contains the \texttt{main} function after all functions have been analyzed.
Furthermore, the code in listing \ref{lst:analyzer_sig_main} validates the \texttt{main} function's signature.
\TSListing[first line=404, last line=419, caption={Analyzer Validating The Signature Of The \texttt{main} Function}, label={lst:analyzer_sig_main}, float=H]{rush/crates/rush-analyzer/src/analyzer.rs}
During traversal of function bodies, the analyzer encounters two \texttt{let} statements in line two and three.
For analyzing these types of statements, the corresponding function is called.
First, the initializing expression of the let-statement is analyzed in order to obtain information about it's result data type.
After the subtree of the expression has been traversed and analyzed, its data type is now known.
The analyzer now inserts a new entry for the variable's name (e.g. \texttt{two}) into its current scope.
Among other data, this entry includes the variable's data type, which was obtained by prior analysis of the expression.
However, we have not yet explained how type annotation works in the analyzer.
In order to get an understanding of how the analyzer determines types of variables, we must consider how expressions are traversed.
The code in listing \ref{lst:analyzer_expr} is part of the method responsible for analyzing expressions.

\TSListing[first line=1007, last line=1013, caption={Analysis Of Expressions During Semantic Analysis}, label={lst:analyzer_expr}, float=H]{rush/crates/rush-analyzer/src/analyzer.rs}

The \texttt{node} parameter specifies the expression node generated by the parser,
it does not yet contain any type information since it is yet to be analyzed.
It is also apparent that the method returns a value of the type \texttt{AnalyzedExpression},
which represents an analyzed and annotated expression.
Therefore, this method consumes a non-analyzed expression and transforms it into an analyzed version of itself.
In this function, the recursive tree-traversal algorithm used in the semantic analyzer is clearly visible.
For instance, if the current expression is a block-expression (line 1009), the responsible method is called.
Since rush allows blocks which contain expressions, a block containing another block is a legal construct.
Therefore, it is possible that the \texttt{expression} method calls itself multiple times recursively.
For most other tree-traversing methods, this recursive behavior is mostly identical as most AST nodes may contain themselves.

For simple types of expressions like integers or floats further analysis is omitted.
Since these types of expressions are constant, the function direcly returns an analyzed version of the expression.
Since we have now explained how tree traversal and analysis works in general, the question of how types are saved in the new tree remains.
\TSListing[first line=129, last line=146, caption={Obtaining The Type Of Expressions}, label={lst:expr_type_impl}, float=H]{rush/crates/rush-analyzer/src/ast.rs}
The code in listing \ref{lst:expr_type_impl} shows how the type of any kind of analyzed expression can be obtained.
For constant expressions like \verb|AnalyzedExpression::(_)|, the determination of its type is straight-forward.
Here, the \texttt{result\_type} function returns \verb|Type::Int(0)|.
In this implementation, \texttt{Type} enum saves a count which specifies the number of pointer indirections.
For instance, the rush type \texttt{**int} is represented as \verb|Type::Int(2)| because there are two levels of pointer indirection.
However, if the method is called on a constant integer expression, the resulting level of pointer indirection is zero.
Therefore, this method is able to return the types of simple constant expressions.
For more complex expressions like if-expressions,
the corresponding analyzed AST node saves its result type directly.
For instance, during analysis of block expressions,
the corresponding function checks if the block contains a trailing expression.
If this is the case, the result type of the block expression is identical to the one of its trailing expression.
This way, the analyzer is able to get type information about each node of the tree after it has been analyzed.

\textcolor{red}{TODO: continue work here}
