\section{Using LLVM for Code Generation}

LLVM is a software project intended to simplify the construction of a compiler generating highly-performant output programs.
It originally started as a research project by \emph{Chris Lattner} for his master's thesis at the University of Illinois at Urbana-Champaign \cite{Lattner:MSThesis02}.
Since then, the project has been widely adopted by the open source community.
In 2012, the project was rewarded the \emph{ACM Software System Award}, a prestigious recognition of significant software which contributed to science.
From the point where popularity of the framework grew, it was renamed from \emph{Low Level Virtual Machine} to the acronym it is known by today.
Today, it can be recognized as one of the largest open source projects \cite[preface]{Cardoso_Lopes2014-jt}.
Among many other projects, the Rust programming language depends on the LLVM compiler in order to generate its target-specific code \cite[p.~373]{McNamara2021-hz}.
Furthermore, the \emph{Clang} C / C++ compiler uses LLVM as its code generating backend \cite[preface]{Hsu2021-ez}.
Therefore, production ready compilers for popular programming languages have been implemented using the LLVM framework.
Besides open-source projects, many companies also use LLVM in their commercial software.
For instance, since 2005, Apple has started incorporating LLVM into some of its products. \cite[pp.~11-15]{Fandrey}.
A recent example of software developed by Apple which uses LLVM is the \emph{Swift} programming language which is mainly used for developing IOS apps \cite[preface]{Hsu2021-ez}.

\subsection{The Role of LLVM in a Compiler}

In a compiler system using LLVM, it is responsible for generating target-specific code.
Furthermore, LLVM is known for performing very effective optimizations during code generation so that the translated program runs faster at runtime and uses less memory.
In order to use LLVM, the system provides and API which is usable by earlier steps of compilation.
Typically, a compiler frontend must only analyze the source program to create an AST.
Therefore, LLVM represents the \emph{back end} of a compiler system.
Then, the AST is traversed and the API of LLVM is used to construct an intermediate representation of the program so that the system can understand it.
Next, LLVM compiles the input program to an arbitrary target architecture.
As of today, LLVM features many target architectures so that a compiler designer does not have to worry about portability of the output program \cite[preface]{Hsu2021-ez}.
Listing \ref{fig:compilation_steps_llvm} shows how LLVM integrates into the previously discussed steps of compilation.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[node distance=3mm and 1cm, inner sep=3mm]
		\node (syntactic_analysis_text) [inner sep=0] {syntactical analysis};
		\node (lexical_analysis) [rec, below=of syntactic_analysis_text] {lexical analysis};
		\node (syntactic_analysis) [rec, fit={(syntactic_analysis_text) (lexical_analysis)}] {};

		\node (semantic_analysis) [rec, right=of syntactic_analysis] {semantic analysis};
		\draw [arrow] (syntactic_analysis) -- (semantic_analysis);

		\node (llvm) [rec, right=of semantic_analysis] {LLVM};
		\draw [arrow] (semantic_analysis) -- (llvm);
	\end{tikzpicture}
	\caption{Steps of Compilation When Using LLVM}
	\label{fig:compilation_steps_llvm}
\end{figure}

% - provides an abstraction layer X
% - optimization and code generation X
% - contains thousand different APIs

% - insert graphic (stages of compilation) with LLVM here X

% - More on optimization is found in Lattner:p.5


\subsection{The LLVM Intermediate Representation}

The intermediate representation (\emph{IR}) represents the source program in a low-level but target-independent way.
Through the use of the LLVM intermediate representation, high-level type information is preserved while the benefits of a low-level representation are introduced.
This allows LLVM to perform significant more aggressive optimizations at compile time compared to other compiler solutions.
Furthermore, LLVM communicates a lot of information to the linker.
As a result of this, many so called \emph{link time optimizations} can be achieved which are not present in most other compilers \cite[p.~5]{Lattner:MSThesis02}.
Therefore, programs compiled using LLVM as the backend will often run significantly faster due to the many aggressive optimizations introduced by the system.

% - target-independent Intermediate Representationfor program analysis X
% - Alternative representation of the program to be compiled X
% - LLVM provides many libraries for interacting with the Ir X

% - The IR is used to represent the source program in a target-independent way 
LLVM provides many APIs for interacting with the IR in memory, so that it can be created by a compiler frontend without it being written onto a file.
The official API for LLVM is for C++ and C.
However, there are many inofficial bindings, such as for Rust, Go, or Python.
For instance, a compiler frontend written in Rust can leverage LLVM although the system is written in C++.
A program represented using the IR always obeys the following hierarchy:

\begin{itemize}
	\item The top most hierarchical structure is the so called \emph{module}.
	      It represents the current file being compiled.
	\item Each module contains several \emph{functions}.
	      Often, each function in the source program is represented using a function in the LLVM IR.
	\item Each function contains several \emph{basic blocks}.
	      Each basic block contains a sequence of instructions.
	      Each block always has to be terminated using a jumping or returning instruction.
	      However, a block must never be terminated twice.
	\item As mentioned above, each basic block contains a sequence of \emph{instructions}.
	      Each instruction holds a semantic meaning and represents a part of the source program.
\end{itemize} \cite[p.~211-213]{Hsu2021-ez}.

% - A program represented using LLVM IR always obeys a hierarchy: module -> function -> basic block -> instruction
% - A module is the file being compiled
% - A function is often similar to one in the source language

% - A basic block is a block of instructions which does not diverge
% - Each block must be terminated using either a jumping or returning instruction
% - A block may not be terminated twice (e.g. break in the loop body)


The IR provides a low-level enough representation in order to allow optimizations in the early stages of compilation.
However, due to the high-level type information contained in a program represented using the IR,
LLVM is able to perform many aggressive optimizations on the IR during later stages of compilation.
This way, LLVM can communicate a lot of information to the linker which can then use this information for link-time optimizations.
The virtual instruction set of LLVM is therefore designed as a low-level representation with high-level type information.
This instruction set represents a virtual architecture which is able to represent most common types processors.
However, the IR avoids machine specific constaints like register-count or low-level calling conventions.
The virtual architecture provides an infinite set of virtual registers which can hold the value of primitives like \emph{integers}, \emph{floating-point numbers}, and \emph{pointer}.
All registers in the IR use the \emph{SSA}\footnote{Short for \enquote{static single assignment}, widely used in optimizing compilers} form in order to allow more optimizations.
In order to enforce the correctness of the type information included in the IR,
the operands of an instruction all obey LLVMs type rules \cite[p.~14-17]{Lattner:MSThesis02}.

% - LLVM is able to perform aggressive optimizations at runtime due to the type information preserved in the IR
%- An IR must be low-level enough so that enough optimizations can be made in the early phases of compilation
%- However, the IR should also be high-level enough so that it supports aggressive link-time optimizations.
%- The Virtual instruction set is therefore designed as a low-level representation with high-level type information
%- this instruction set represents a virtual architecture which is able to represent most ordinary processors but avoids machine specific constaints (registers / calling conventions)
%- Registers use static single assignment form (SSA) (widely used for compiler optimization)
%- Values can be stored in memory (stack) using the load / store instructions
%- Three address code
%- Every instruction has an associated type, all operations obey type rules

%\cite[p.~14-17]{Lattner:MSThesis02}

In order to understand how the LLVM IR represents a program, we now consider the calculation of Fibonacci numbers again.
For reference, the rush program used in this example can be found in Listing \ref{lst:rush_fib} on page \pageref{lst:rush_fib}.
The code in Listing \ref{lst:llvm_fib} displays LLVM IR representing this rush program.
The IR was generated by the LLVM targeting rush compiler\footnote{Generated in git commit \rushCommit}.

\TSListing[first line=5, caption={LLVM IR Representation of the Program in Listing \ref{lst:rush_fib}}, label={lst:llvm_fib}, float=H]{listings/generated/fib.ll}

The code displayed in the listing is part of a LLVM module.
In the lines 5 and 29, functions are defined using the \texttt{declare} keyword.
It is apparent that the functions in the LLVM module represent the functions from the source rush program.
Furthermore, if we examine the signature of the \texttt{fib} function in line 5 of the IR,
it becomes apparent that the function returns a \texttt{i64}.
In rush, each \texttt{int} can hold 64 bit signed numbers, therefore the \texttt{i64} LLVM type represents the rush \texttt{int} type.
Furthermore, we can observe that the function takes a i64 parameter named \texttt{\%0}.
This parameter represents the \texttt{n} parameter in our rush source program.

In line 6, the start of the \enquote{entry} block of the \texttt{fib} function is declared using the block's name followed by a colon.
Since LLVM can perform more optimizations on variables if they are declared in the \texttt{entry} block of a function,
out compiler uses the \texttt{entry} block solely for variable declarations.
In line 7, the block is terminated using the \texttt{br}\footnote{Short for \enquote{branch}} instruction.
This instruction jumps to the beginning of the block specified in its operand.
In this case, the target of the jump is the beginning of the \texttt{body} basic block in the same function.
Due to constraints introduced by its internal optimizations, LLVM only allows targeting blocks contained in the same function.

In line 10, the \texttt{icmp slt}\footnote{Short for \enquote{integer compare (signed less than)}} is used in order to compare the runtime value of the parameter \texttt{\%0} to a constant 2.
The boolean result is then saved in the virtual register \texttt{\%i\_lt}.
Here, it becomes apparent that LLVM's vitual registers can be given arbitrary names.
In places where this is possible, our compiler will use names which will make reading the IR easier for humans.
In line 11, another branch-instruction is used.
However, this time, the jump is placed under the condition that the value of \texttt{\%i\_lt} is true.
Here, we can see that LLVM instructions are able to operand on different type of operands depending on what the instruction should do.
Furthermore, the \texttt{else} label is also an operand of the branch-instruction.
This is because conditional jumps in LLVM always require an alternative jump to perform if the condition is false at runtime.
As the names \texttt{then} and \texttt{else} suggest, this branch-instruction presents the essential part of the if-expression in the source program.
If the condition was true at runtime, the instruction would jump to the \texttt{then} block.
However, this block only contains one instruction jumping to the \texttt{merge} block.

In line 17, the \texttt{phi} instruction is used.
These so called $\phi$-nodes are necessary due to the SSA form used in the LLVM IR.
In short, a \emph{phi-node} produces a different value depending on the basic block where control came from.
Since the if-construct is an expression in rush, LLVM must know if the result of the \texttt{then} or the \texttt{else} branch is to be used as the result of the entire if-expression.
As a solution to this problem, these phi-nodes associate a value to a origin branch.
In this example, the phi-node yields the value of the parameter \texttt{\%0} (\texttt{n}) if control came from the \texttt{then} block.
In the source program, \texttt{n} should be returned without modification if it is less than 2.
Therefore, the runtime result of the phi-node is \texttt{\%0} if it is less than 2 at runtime.
Otherwise, if control came from the \texttt{else} block, the phi-node's result is taken from the virtual register \Verb|\%i_sum3|.
However, we have not covered where this virtual register is declared.
For this, we consider the instructions in the \texttt{else} block, starting in line 21 with the \texttt{sub} instruction.
In this case, the instruction subtracts 2 from the parameter \texttt{\%0} and saves the result in \Verb|\%i_sum|.
This is done in order to create the argument value for the first recursive call to \texttt{fib}.
Next, the \texttt{call} instruction is used in order to perform the recursive call.
Here, the \Verb|\%i_sum| register is used as an argument to the call-instruction.
The return value of the function call is saved in the \Verb|\%ret_fib| register.
The same behavior is used in order to call \texttt{fib(n - 1)}.
However, in that case, 1 is subtracted from the parameter and saved in \Verb|\%i_sum1|.

Next, the \texttt{add} instruction in line 25 is used in order to calculate the sum of the return values of the recursive calls
This sum is then saved in the virtual register \Verb|\%i_sum3|.
Therefore, this register is used in the phi-node in line 17 so that the result of the recursive calls is used as the result of the if-expression.
Finally, the \texttt{ret} instruction in line 18 is used in order to use the result of the if-expression as the return-value of the function.

Since the \texttt{main} function does not introduce any new concepts, we will omit detailed explaination of its contents.
However, in line 36, the \texttt{unreachable} instruction is used in order to state that it is never executed.
This is necessary because LLVM requires that every basic block needs to terminated.
The \texttt{exit} function terminates the program using a system call and therefore terminates the basic block.
However, LLVM does not regard call-instructions as diverging and therefore disallows the call to \texttt{exit} as a way to terminate the basic block.
Since LLVM does not known that the \texttt{exit} function terminates program execution, an \texttt{unreachable}  instruction is inserted to communicate a block termination to LLVM.

By considering the example from above, it became apparent that the IR represents many source language constructs in a high-level way.
For instance, function calls can be used without considering the complex rules introduced by low-level calling conventions.
Here, calling and returning from a function can be implemented using very little effort.
Furthermore, virtual registers allow the compiler frontend to ommit register allocation entirely.
Lastly, the LLVM IR can subjectively be seen as very readable since registers, basic blocks, and functions may contain custom, human-readable labels.
Moreover, most instructions have a relatively reasonable name which allows readers to guess what the instruction is doing without them reading any LLVM documentation.


\subsection{The rush Compiler Using LLVM}

In order to get accquainted to the LLVM framework in a practical way, we have implemented a rush compiler which uses the framework as its backend.
However, the first problem emerged soon since the LLVM project only provides official C / C++ bindings to be used by other programs.
Nonetheless, the entire rush project is written in the Rust programming language.
Therefore, a third-party Rust wrapper around LLVM is required.
We have settled on using the \emph{Inkwell} rust crate since it exposes a safe rust API for using LLVM for code generation \cite{Inkwell2023}.

To understand how this rush compiler leverages LLVM in order to translate programs, we should first consider some implementation details.
The code in Listing~\ref{lst:llvm_cmp_struct} displays the top part of the `\texttt|Compiler|' struct definition.

\TSListing[first line=26, last line=29, caption={Struct definition of the rush LLVM \texttt{Compiler}}, label={lst:llvm_cmp_struct}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

The \texttt{context} field in line 27 represents a container for all LLVM entities including modules.
Next, the \texttt{module} field contains the underlying LLVM module.
In line 29, the \texttt{builder} field contains a helper struct provided by LLVM which allows generation of IR whilst only using in-memory structures.
All the types of the above fields are provided by the Inkwell crate and are therefore used to interact with the framework.
In order to get a deeper understanding of how this compiler works exactly, we will now consider how the program in Figure~\ref{fig:llvm_simple} is translated into IR.

\noindent
\begin{figure}[h]
	\begin{minipage}{.5\textwidth}
		\centering
		\TSListing[frame=none]{listings/simple.rush}
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		\centering
		\TSListing[first line=5, frame=none]{listings/generated/simple.ll}
	\end{minipage}
	\caption{Translation of a Simple rush Program to LLVM IR}
	\label{fig:llvm_simple}
\end{figure}

In the source program on the left side, the two variables \texttt{two} and \texttt{three} are defined.
Then, the program exits using the sum of these two variables.

\TSListing[first line=862, last line=868, caption={Compilation of Expressions Using LLVM}, label={lst:llvm_exprs}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
	\item \TODO{Function uses analyzed expr and produces a LLVM value}
	\item \TODO{How a basic int is created}
\end{itemize}

\TSListing[first line=311, last line=317, caption={Compilation of the `\texttt{main}' Function Using LLVM}, label={lst:llvm_main_fn}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
	\item \TODO{Explain function signature + add function to module}
\end{itemize}

\TSListing[first line=598, last line=613, caption={Compilation of Let-Statements Using LLVM}, label={lst:llvm_let}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
	\item \TODO{RHS is compiled first}
	\item \TODO{In case the variable is mutable, it is put onto the stack}
	\item \TODO{Uses the \texttt{alloc\_ptr} helper method}
	\item \TODO{Stores the value of the init expression in the pointer}
	\item \TODO{Lastly, the variable is inserted into the scope}
\end{itemize}

\TSListing[first line=622, last line=638, caption={Pointer Allocation in the LLVM Compiler}, label={lst:llvm_ptr_alloc}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
    \item \TODO{Describe method signature and why the method exists}
    \item \TODO{Stack access in LLVM is used by accessing pointer values}
    \item \TODO{Using stack space is extremely simple}
    \item \TODO{Explain what the builder position does}
\end{itemize}

\TSListing[first line=1009, last line=1011, caption={Compilation of Integer Infix-Expressions Using LLVM}, label={lst:llvm_infix}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
    \item \TODO{Simple arithmetic operations are relatively simple and involve one call}
    \item \TODO{Explain the builder pattern}
\end{itemize}

\TSListing[first line=940, last line=943, caption={Compilation of Call-Expressions Using LLVM}, label={lst:llvm_call}, float=H]{deps/rush/crates/rush-compiler-llvm/src/compiler.rs}

\begin{itemize}
    \item \TODO{Function calls are implemented like this}
    \item \TODO{Previously, the \texttt{func} variable was declared by retrieving the function from the module}
    \item \TODO{The \texttt{args} variable is a \Verb|Vec<BasicMetadataValueEnum>| and was created previously}
    \item \TODO{Also shows how custom names can be given to registers}
\end{itemize}

% - Use of inkwell X
% - Example program

\subsection{Final Code Generation: The Linker}

% - Explain linking
% - Difference `.o` vs binary
% - LLVM's link-time optimizations
% - https://en.wikipedia.org/wiki/Linker_(computing)

\subsection{Conclusions}

% - Explain what was difficuilt and what was good
% - Benchmark: fib LLVM vs x86_64
