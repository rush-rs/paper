In Chapter 2, we have learned how the syntactical and semantic analysis play a vital role before program execution can start.
We have explained how the \emph{parser} is used for analyzing the program's syntax in order to construct an AST.
Furthermore, it has been explained how the \emph{semantic analyzer}, validates the program's semantic rules.

Next, in Chapter 3, we have explained how a tree walking interpreter and a virtual machine can be leveraged to execute programs using an interpreter.
Here, the tree walking interpreter has presented itself as the easier solution, both in planning and implementation.
The virtual machine however has proven itself to be slightly more demanding as it requires a custom-made compiler to execute programs.
However, we have concluded that a VM often executes a program faster.

Chapter 4 provided an overview of compilation to high-level targets.
As examples for high-level targets, \emph{WASM} and \emph{LLVM} have been used.
The former has proven itself to be \TODO{What about WASM}.
During planning and implementation of rush, leveraging LLVM has proven itself to make implementation of a high-performance, multi-target compiler both feasible and easy.
To summarize, writing a compiler targeting these high-level targets presented a demanding but accomplishable task.
If we were to construct a compiler for a more complicated language, LLVM would present an attractive solution considering its current relevance in the software industry.
In Chapter 5, low-level programming concepts and compilation to low-level targets have been covered.
During the research and implementation phase of this paper,
this chapter has proven itself to be the most demanding by far.
Reasons for this are that writing a compiler targeting a low-level architecture
requires detailed knowledge about the target machine, thus making the implementation process much harder.
Furthermore, programming on the assembly level often creates bugs which are hard to eliminate for a programmer who is used to writing software in high-level languages.
As a result of this, we have both spent many hours trying to locate subtle bugs in our compiler which were rooted on the assembly level.
Moreover, creating a low-level compiler which emits efficient code has proven to be very difficult.
Therefore, our low-level compilers only focus on the minimal principles without regarding optimization techniques.
Like initially expected, implementation of the x86 compiler has proven to be more demanding than the implementation of the \riscv{} compiler.
Among other factors, this is because \riscv{} is a modern architecture which was designed with the compilers targeting them in mind.
On the contrary, x86 is a very old architecture which has evolved over time but was created when assembly programs were still written by hand.

To summarize, this paper has presented two vastly different means of program execution,
the former being an interpreter and the latter being a compiler.
In order to demonstrate the differences using practical examples,
we have implemented our own programming language called \emph{rush}.
In summary, we have implemented two rush compilers, two interpreters, four compilers, and one transpiler.
Additionally, we have implemented additional tooling like a language server, web playground, and command line interface combining all components.
Real programming languages often implement a lot more tooling like dependency managers, build systems, intricate analyzers, and formatters.
Since this paper is primarily about methods of program execution, a reader interested in this tooling might browse the rush Github organization (\url{https://github.com/rush-rs}).
