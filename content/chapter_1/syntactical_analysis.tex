% chktex-file -2
\section{Lexical and Syntactical Analysis}

As previously mentioned, the first step during compilation or program execution consists of the \emph{lexical} and \emph{syntactical analysis}.
Program source text is, without previous processing, just \emph{text}, i.e., a sequence of characters.
Before the computer can even begin to analyze the semantics and meaning of a program, it has to first \emph{parse} the program source text into an appropriate data structure.
This is done in two steps that are closely related and often combined.
The \emph{lexical analysis}, performed by a \emph{lexer}, and the \emph{syntactical analysis}, performed by a \emph{parser}.

\subsection{Formal Syntactical Definition by a Grammar}

Just like every natural language, most programming languages also conform to a grammar.
However, grammars for programming languages are most often of type 2 or 3 in the Chomsky hierarchy, that is \emph{context-free} and \emph{regular} languages, whereas natural languages often are type 1 or 0~\cite[p.~24]{Watson2017}.
Additionally, it is not uncommon for parser writers to formally define the grammar using some notation.
Popular options include \emph{BNF}\footnote{\enquote{Backus-Naur Form}, named after the two main inventors~\cite{Backus1960}.} and \emph{EBNF}\footnote{\enquote{Extended Backus-Naur Form}, an extended version of \emph{BNF} with added support for repetitions and options without relying on recursion, first proposed by Niklaus Wirth in 1977~\cite{Wirth1977} followed by many slight alterations. The version used in this paper is defined by the ISO/IEC 14977 standard.}, the latter of which we use here.
Although this paper does not fully explain these notations, Listing~\ref{lst:ebnf_reference_grammar} shows a short example grammar notated using EBNF.
For reference, Appendix~\ref{apx:grammar} contains the full grammar of rush.
\TODO{example for type 1 language \qVerb{([)]}?}
\TODO{explain start symbol?}
\TODO{formal definition of grammars $G=(N,T,S,P)$?}

\Lirsting[float=h, caption={Grammar for basic arithmetic in EBNF notation.}, label={lst:ebnf_reference_grammar}]{listings/ebnf_reference.ebnf}

One thing worth explaining is the \qVerb{-} at the end of line 5.
It is used to exclude a set of symbols from the preceding rule.
As there is no symbol following the dash in this case, the empty word, called $\epsilon$, is excluded from the preceding repetition.
Thus, the repetition cannot be repeated zero times here, as that would produce the empty word, which is excluded.
So the notation \qVerb{{ ... }-} is used to represent repetitions of one or more times, whereas the same without the trailing dash represents repetitions of zero or more times.

\subsection{Grouping Characters Into Tokens}

Before the syntax of a program is validated, it is common to have a lexer group certain sequences of characters into \emph{tokens}.
The set of tokens a language provides is the union of the set of all terminal symbols used in context-free grammar rules and the set of regular grammar rules.
For the language defined in Listing~\ref{lst:ebnf_reference_grammar} these are the five operators \qVerb{+}, \qVerb{-}, \qVerb{*}, \qVerb{/}, \qVerb{**}, and the `integer' non-terminal.

\Lirsting[ranges={10-16}, wrap=L, wrap width=0.4\textwidth, caption={The rush \qVerb{Lexer} struct definition.}, label={lst:lexer}]{deps/rush/crates/rush-parser/src/lexer.rs}

The specifics of implementing a lexer are not explored in this paper, but a basic overview is still provided.
The base principle of a lexer is to iterate over the characters of the input to produce tokens.
Depending on the target language, it might be required to scan the input using an $n$-sized window, i.e., observing $n$ characters at a time.
In the case of rush, this $n$ is `2', resulting in the \qVerb{Lexer} struct not only storing the current character, but also the next character, as seen in Listing~\ref{lst:lexer}.
For clarity, Table~\ref{tbl:lexer} shows the values of \qVerb{curr_char} and \qVerb{next_char} during processing of the input \qVerb{1+2**3}.
Here every row in the table represents one point in time displaying the lexer's current state.

\begin{table}[h]
	\newcommand{\lexerframe}[8][]{\tikz[baseline={(frame.base)}]{
			\node(frame)[stack=6, rectangle split part fill={#2}, #1]{
				\texttt{#3}
				\nodepart{two}\texttt{#4}
				\nodepart{three}\texttt{#5}
				\nodepart{four}\texttt{#6}
				\nodepart{five}\texttt{#7}
				\nodepart{six}\texttt{#8}
			};
			% fix margin around tikzpicture
			\node[fit={(current bounding box)}, inner ysep=.5mm, inner xsep=0]{};
		}}
	\centering
	\caption{Advancing window of a lexer.}\label{tbl:lexer}
	\begin{tabularx}{0.95\textwidth}{rCLLl}
		Calls & State                                                                                                                                                     & \colorbox{black!20}{\Verb{curr_char}} & \colorbox{black!10}{\Verb{next_char}} & Output Token  \\
		\\[-1.1em]\hline\\[-1.1em]
		0     & \lexerframe{none}{1}{+}{2}{*}{*}{3}                                                                                                                       & \Verb{None}                           & \Verb{None}                           &               \\
		0     & \lexerframe{black!10,none}{\bfseries1}{+}{2}{*}{*}{3}                                                                                                     & \Verb{None}                           & \Verb{Some('1')}                      &               \\
		0     & \lexerframe{black!20,black!10,none}{\bfseries1}{\bfseries+}{2}{*}{*}{3}                                                                                   & \Verb{Some('1')}                      & \Verb{Some('+')}                      &               \\
		1     & \lexerframe{none,black!20,black!10,none}{\color{black!50}1}{\bfseries+}{\bfseries2}{*}{*}{3}                                                              & \Verb{Some('+')}                      & \Verb{Some('2')}                      & \Verb{Int(1)} \\
		2     & \lexerframe{none,none,black!20,black!10,none}{\color{black!50}1}{\color{black!50}+}{\bfseries2}{\bfseries*}{*}{3}                                         & \Verb{Some('2')}                      & \Verb{Some('*')}                      & \Verb{Plus}   \\
		3     & \lexerframe{none,none,none,black!20,black!10,none}{\color{black!50}1}{\color{black!50}+}{\color{black!50}2}{\bfseries*}{\bfseries*}{3}                    & \Verb{Some('*')}                      & \Verb{Some('*')}                      & \Verb{Int(2)} \\
		4     & \lexerframe{none,none,none,none,black!20,black!10}{\color{black!50}1}{\color{black!50}+}{\color{black!50}2}{\color{black!50}*}{\bfseries*}{\bfseries3}    & \Verb{Some('*')}                      & \Verb{Some('3')}                      &               \\
		4     & \lexerframe{none,none,none,none,none,black!20}{\color{black!50}1}{\color{black!50}+}{\color{black!50}2}{\color{black!50}*}{\color{black!50}*}{\bfseries3} & \Verb{Some('3')}                      & \Verb{None}                           & \Verb{Pow}    \\
		5     & \lexerframe{none}{\color{black!50}1}{\color{black!50}+}{\color{black!50}2}{\color{black!50}*}{\color{black!50}*}{\color{black!50}3}                       & \Verb{None}                           & \Verb{None}                           & \Verb{Int(3)} \\
	\end{tabularx}
\end{table}

As explained in Section~\ref{sec:stages_of_compilation}, many modern language implementations have the lexer produce tokens on demand.
Thus, a lexer requires one public method, \qVerb{next_token} for instance, reading and returning the next token.
In Table~\ref{tbl:lexer} the column on the left displays how many times the \qVerb{next_token} method has been called by the parser.
In the first three rows, this count is still `0', as this happens during initialization of the lexer in order to fill the \qVerb{curr_char} and \qVerb{next_char} fields with sensible values before the first token is requested.
The \qVerb{Pow} token, composed of two \qVerb{*} characters, requires the lexer to advance two times before it can be returned, which is represented by the two rows in which the call count is `4'.
A simplified \qVerb{Token} struct definition for the example language from Listing~\ref{lst:ebnf_reference_grammar} is shown as part of Listing~\ref{lst:token_simple}.

\Lirsting[wrap=L, wrap width=0.3\textwidth, caption={Simplified \qVerb{Token} struct definition.}, label={lst:token_simple}]{listings/token_simple.rs}

In addition to the current and next character, a lexer also has to keep track of the current position in the source text for it to generate helpful messages with locations in case the program is syntactically malformed.
This is done in the \qVerb{location} field which is incremented every time the lexer advances to the next character.
While producing a token, the lexer can read this field once at the start and once after having read the token, and save the two values as the token's span.

A special case worth mentioning are comments.
As explained later in Section~\ref{sec:constructing_a_tree}, depending on the parser, comments may be simply ignored and skipped during lexical analysis, or get their own token kind and be treated similar to string literals.

\TODO{maybe mention having spans inclusive or exclusive}

\subsection{Constructing a Tree}\label{sec:constructing_a_tree}

The parser uses the generated tokens in order to construct a tree representing the program's syntactic structure.
Depending on how the parser should be used, this can either be a \emph{Concrete Syntax Tree} (CST) or an \emph{Abstract Syntax Tree} (AST).
The former still contains information about all input tokens with their respective locations, while the latter only stores the abstract program structure, focusing on just the relevant information for basic analysis and execution.
Therefore, a CST is usually used for development tools like formatters, intricate linters, and analyzers, where it is important to preserve stylistic choices made by the programmer, for which knowing the exact location of every token is beneficial.
However, an AST is enough for interpretation and compilation as it preserves the semantic meaning of the program.
Figure~\ref{fig:parser_simple_ast} shows an AST for the program \qVerb{1+2**3} in the language notated in Listing~\ref{lst:ebnf_reference_grammar} on page~\pageref{lst:ebnf_reference_grammar}.
In the case of rush, an AST with limited location information is used, because rush's semantic analyzer is basic enough to not require precise locations of every token, and, as discussed, execution and compilation requires no CST.

\begin{wrapfigure}{R}{0.5\textwidth}
	\centering
	\begin{tikzpicture}[level distance=1cm, sibling distance=2cm]
		\node {Expression}
		child {node {Term}
				child {node {Factor}
						child {node {\Verb{Int(1)}}}}}
		child {node {\Verb{Plus}}}
		child {node {Term}
				child {node {Factor}
						child {node {\Verb{Int(2)}}}
						child {node {\Verb{Pow}}}
						child {node {Factor}
								child {node {\Verb{Int(3)}}}}}};
	\end{tikzpicture}
	\caption{Abstract syntax tree for `\texttt{1+2**3}'.}\label{fig:parser_simple_ast}
\end{wrapfigure}

However, not every parser is the same, and there are a number of different strategies for implementing one, depending on the requirements of the language.
These strategies are categorized into \emph{top-down parsers} and \emph{bottom-up parsers}.
The main difference between them is the kind of tree traversal they perform.
Top-down parsers construct the syntax tree in a pre-order manner, meaning a parent node is always constructed before its children nodes.
\TODO{well, \emph{construction} uses post-order, but the method calls are pre-order}
Hence, the syntax tree is constructed from top to bottom, starting with the root node.
Bottom-up parsers instead perform post-order traversal.
That way, all child nodes are processed before their parent node.
This results in the tree being constructed from the leafs at the bottom upwards to the root.
\TODO{a non-exisiting tree cannot be traversed}

Top-down and bottom-up parsers are further categorized into many more subcategories.
The two discussed here are so-called \emph{LL$(k)$} parsers and \emph{LR$(k)$} parsers.
These are named after the direction of reading the tokens, `L' being from left to right, and the derivation they use.
`L' is the leftmost derivation and `R' the rightmost derivation.
\TODO{what are derivations? + citation can be found here \cite[pp.~75f]{Watson2017}}
The parenthesized $k$ represents a natural number with $k\in\mathbb{N}_0$, describing the number of tokens for \emph{lookahead}.
Often, $k$ is either `1' or `0', forming a two or one wide window respectively.
This window moves just like previously explained for the lexer, and observes $k$ tokens, not characters, simultaneously.
Since in most cases $k$ is `1', it is common to omit specifying it and to just speak of `LL' and `LR' parsers~\cite[pp.86-88]{Watson2017}.

Alternatively to using lookahead tokens, it is possible to create parsers utilizing backtracking.
With that approach, a parser has to guess which syntax construct follows if it cannot decide based on the first token.
Later, when the parser detects an unexpected symbol, instead of throwing a syntax error, it cancels and returns to the point of decision-making to try the next possible construct.
This usually comes with overhead and unclear error messages, which is why this method is rarely used and the superior lookahead method is preferable.

An example for LR parsing is the \emph{shift-reduce} parsing approach, which is later outlined on page~\pageref{sec:parser_generators}.
However, it is to be noted that LR parsers are generally very complicated to implement manually.
On the contrary, LL parsers are usually much simpler to implement, but come with a limitation.
By design, they must recognize a node by its first $n=k+1$ tokens, where $n$ is the window size.
However, due to that restriction, not every context-free language can be parsed by an LL parser.
An example for that is given in Listing~\ref{lst:ebnf_reference_pratt}.
\TODO{explain why}

\Lirsting[float=h, caption={Example language a traditional LL$(1)$ parser cannot parse.}, label={lst:ebnf_reference_pratt}]{listings/ebnf_reference_pratt.ebnf}

Most LL parsers, including rush's, are \emph{recursive-descent} parsers.
Implementation of such a recursive-descent parser is rather uncomplicated.
Assuming the grammar respects the mentioned limitation and that an object-oriented approach is used, every context-free grammar rule is mapped to one method on a \qVerb{Parser} struct.
In the example grammar from Listing~\ref{lst:ebnf_reference_grammar} on page~\pageref{lst:ebnf_reference_grammar}, these are all the capitalized rules highlighted in yellow.
Additionally, a matching node type is defined for each context-free rule, holding the relevant information for execution.
For Rust, mapping from EBNF grammar notation to type definitions is very simple.
Some examples are displayed in Table~\ref{tbl:ebnf_to_rust}.
\TODO{explain some of them}
\TODO{struct signature example?}

\begin{table}[h]
	\caption{Mapping from EBNF grammar to Rust type definitions.}\label{tbl:ebnf_to_rust}
	\rowcolors{2}{gray!15}{}
	\begin{tabularx}{0.95\textwidth}{Ll}
		\rowcolor{gray!25} EBNF                         & Rust                                                                         \\
		\hline
		\LirstInline{ebnf}{A = B , C ;}                 & \LirstInline{rs}{struct A { b: B, c: C }}                                    \\
		\LirstInline{ebnf}{A = B , [ C ] ;}             & \LirstInline{rs}{struct A { b: B, c: Option<C> }}                            \\
		\LirstInline{ebnf}{A = B , { C } ;}             & \LirstInline{rs}{struct A { b: B, c: Vec<C> }}                               \\
		\LirstInline{ebnf}{A = B , { C }- ;}            & \LirstInline{rs}{struct A { b: B, c: Vec<C> }}                               \\
		\LirstInline{ebnf}{A = B | C ;}                 & \LirstInline{rs}{enum A { B(B), C(C) }}                                      \\
		\LirstInline{ebnf}{A = B , ( '+' | '-' ) , C ;} & \gape{\makecell[l]{\LirstInline{rs}{struct A { b: B, op: Op, c: C }}         \\\LirstInline{rs}{enum Op { Plus, Minus }}}} \\
		\LirstInline{ebnf}{A = B , [ ( X | Y ) , C ] ;} & \gape{\makecell[l]{\LirstInline{rs}{struct A { b: B, c: Option<(XOrY, C)> }} \\\LirstInline{rs}{enum XOrY { X(X), Y(Y) }}}} \\
	\end{tabularx}
\end{table}

\subsubsection{Operator Precedence}

As discussed previously, a traditional LL parser cannot parse the language from Listing~\ref{lst:ebnf_reference_pratt}.
However, when comparing the grammar to Listing~\ref{lst:ebnf_reference_grammar}, it might become obvious that the two grammars notate the same language.
The first one simply provides additional information about the order of nesting different kinds of expressions, called \emph{precedence}.
For example, when parsing the expression \qVerb{1+2*3}, the \qVerb{2*3} part should be nested deeper in the tree for it to be evaluated first.
In Listing~\ref{lst:ebnf_reference_grammar}, this is achieved by recognizing multiplicative expressions as \qVerb{Term}s and having additive expressions be composed of multiple \qVerb{Term}s.
Listing~\ref{lst:ebnf_reference_pratt} does not indicate the order of evaluation itself, so it must be provided externally.

Additionally, a precedence may be either left- or right-associative.
The input \qVerb{1*2*3} should be evaluated from left to right, so first \qVerb{1*2}, and then the result times `3'.
Now consider \qVerb{1**2**3}\footnote{\qVerb{**} is the power operator here, so the input would be written as $1^{2^3}$ using mathematical notation.}.
Here, the \qVerb{2**3} should be evaluated first, and afterwards `1' should be raised to the result.
That means while most operators are evaluated from left to right, that is, they are left-associative, some operators, like the power operator, are evaluated from right to left and are therefore right-associative.
In Listing~\ref{lst:ebnf_reference_grammar}, left-associativity is achieved by allowing simple repetition of the operator for an indefinite amount of times.
Right-associativity instead uses recursion on the right-hand side of the operator.

\begin{wrapfigure}{R}{0.5\textwidth}
	\centering
	\begin{tikzpicture}[level distance=1cm, sibling distance=2cm]
		\node {Expression}
		child {node {Expression}
				child {node {\Verb{Int(1)}}}}
		child {node {\Verb{Plus}}}
		child {node {Expression}
				child {node {Expression}
						child {node {\Verb{Int(2)}}}}
				child {node {\Verb{Pow}}}
				child {node {Expression}
						child {node {\Verb{Int(3)}}}}};
	\end{tikzpicture}
	\caption{Abstract syntax tree for `\texttt{1+2**3}' using Pratt parsing.}\label{fig:parser_simple_ast_pratt}
\end{wrapfigure}

For LR parsers, the precedence and associativity for each operator is encoded within the parser table.
However, there is also a technique called \emph{Pratt parsing}\footnote{First introduced by Vaughan Pratt in 1973~\cite{Pratt1973}.} that allows slightly modified recursive-descent LL parsers to parse such languages, given a map from tokens to precedences and their associativity.
Often, the grammars without included precedence are preferred, because they usually result in a simpler structure of the resulting syntax tree.
This can be seen when comparing Figure~\ref{fig:parser_simple_ast} from earlier to Figure~\ref{fig:parser_simple_ast_pratt} which shows the resulting AST for the same input using the alternative language representation.
Most notably, the rather long sequences of nodes with just a single child, like the path on the left simply resolving to a single \qVerb{Int(1)} token, are gone in Figure~\ref{fig:parser_simple_ast_pratt}.

\subsubsection{Pratt Parsing}

As the rush parser makes use of Pratt parsing, most of the following code snippets are taken from there.
First, a mapping from a token kind to its precedence must be defined.
The one for rush is found in Listing~\ref{lst:rush_tok_prec}.
It shows the \qVerb{prec} method implemented on the \qVerb{TokenKind} enum.
The return type is a tuple of two integers, one for left and one for right precedence.
For all but one token kind, the left precedence is lower than the right one, resulting in left-associativity.
The higher the precedences are, the deeper in the tree the resulting expressions will be, and the earlier they will be evaluated.
All unrelated tokens are simply assigned a precedence of `0' for left and right.

\Lirsting[ranges={172-173, 194-201}, float=h, label={lst:rush_tok_prec}, caption={Token precedences in rush.}]{deps/rush/crates/rush-parser/src/token.rs}

The \qVerb{expression} method on the \qVerb{Parser} struct is then modified to take a parameter for the current precedence as seen in Listing~\ref{lst:pratt_expr}.
It then first matches on the current token kind to decide which expression to parse and stores the result in the \qVerb{lhs}\footnote{Short for \enquote{left-hand side}.} variable.
Afterwards it checks whether the left precedence of the now current token is bigger than the \qVerb{prec} argument.
When called from elsewhere, like in the condition of a while-loop or in a grouped expression, the \qVerb{prec} argument has its minimum value of `0', as shown in Listing~\ref{lst:pratt_grouped_expr}.
In that case, this check will only fail when the whole expression is over, as every non-operator token is assigned a precedence higher than 0.
If it does not fail, the \qVerb{infix_expr} method is called with the matching operator and the \qVerb{lhs}.
Afterwards, \qVerb{lhs} is overwritten with the returned value.

\Lirsting[ranges={551-555, 568-570, _574-583, 613-618}, float=h, label={lst:pratt_expr}, caption={Pratt-Parser: implementation for expressions.}]{deps/rush/crates/rush-parser/src/parser.rs}

\Lirsting[ranges={733-743, 749-749}, float=h, label={lst:pratt_grouped_expr}, caption={Pratt-Parser: implementation for grouped expressions.}]{deps/rush/crates/rush-parser/src/parser.rs}

The \qVerb{infix_expr} method in Listing~\ref{lst:pratt_infix_expr} simply stores the precedence for the right side of the operator token, advances to the next token, and calls the \qVerb{expression} method again for its right-hand side, but this time with the stored \qVerb{right_prec} as the minimum precedence.
These simple calls and checks of precedences automatically result in correct grouping and nesting of the expressions.

\Lirsting[ranges={751-751, _756-759, 770-770}, float=h, label={lst:pratt_infix_expr}, caption={Pratt-Parser: implementation for infix expressions.}]{deps/rush/crates/rush-parser/src/parser.rs}

\begin{figure}[hb]
	\newcommand{\precs}[5][black]{
		\node(tok_#3)[below of=#3]{#2};
		\draw[arrow](#3) -- (tok_#3);

		\node(#3_lprec)[prec, color=#1, below of=tok_#3, xshift=-4mm]{#4};
		\node(#3_rprec)[prec, color=#1, below of=tok_#3, xshift= 4mm]{#5};
		\draw[arrow, color=#1](tok_#3) -- (#3_lprec);
		\draw[arrow, color=#1](tok_#3) -- (#3_rprec);
	}
	\centering
	\begin{tikzpicture}[prec/.style={font=\footnotesize}]
		\node(lparen)                             {\Verb{(}};
		\node(1)     [xshift=5mm, right of=lparen]{\Verb{1}};
		\node(+)     [xshift=5mm, right of=1]     {\Verb{+}};
		\node(2)     [xshift=5mm, right of=+]     {\Verb{2}};
		\node(*)     [xshift=5mm, right of=2]     {\Verb{*}};
		\node(3)     [xshift=5mm, right of=*]     {\Verb{3}};
		\node(rparen)[xshift=5mm, right of=3]     {\Verb{)}};
		\node(/)     [xshift=5mm, right of=rparen]{\Verb{/}};
		\node(4)     [xshift=5mm, right of=/]     {\Verb{4}};
		\node(**)    [xshift=5mm, right of=4]     {\Verb{**}};
		\node(5)     [xshift=5mm, right of=**]    {\Verb{5}};

		\precs[gray]{\Verb{LParen}}{lparen}{28}{29}
		\precs[gray]{\Verb{Int(1)}}{1}     {0} {0}
		\precs      {\Verb{Plus}}  {+}     {19}{20}
		\precs[gray]{\Verb{Int(2)}}{2}     {0} {0}
		\precs      {\Verb{Star}}  {*}     {21}{22}
		\precs[gray]{\Verb{Int(3)}}{3}     {0} {0}
		\precs      {\Verb{RParen}}{rparen}{0} {0}
		\precs      {\Verb{Slash}} {/}     {21}{22}
		\precs[gray]{\Verb{Int(4)}}{4}     {0} {0}
		\precs      {\Verb{Pow}}   {**}    {26}{25}
		\precs[gray]{\Verb{Int(5)}}{5}     {0} {0}
	\end{tikzpicture}
	\caption{Token precedences for the input `\Verb{(1+2*3)/4**5}`.}\label{fig:token_precs}
\end{figure}

In order to understand the concept better, Figure~\ref{fig:token_precs} can be considered.
It shows the tokens with their respective left and right precedence for the input \qVerb{(1+2*3)/4**5}, which represents the mathematical expression $\frac{1+2\cdot3}{4^5}$.
Precedences which are irrelevant for this example have been colored in gray.
Starting from the left, the parser first encounters an \qVerb{LParen} token and therefore decides to parse a grouped expression.
Inside the \qVerb{grouped_expr} method, \qVerb{expression} is called again, with \qVerb{prec} being `0' once more.
The difference is that now the current token is \qVerb{Int(1)}.
That token is then parsed as a simple integer expression and stored in \qVerb{lhs}.
Now, the left precedence of the \qVerb{Plus} token, `19', is higher than the value of \qVerb{prec}, `0', so the while-loop is entered.
In there, the \qVerb{infix_expr} method is called, which queries the right precedence of the \qVerb{Plus} token and calls \qVerb{expression} again, this time with a precedence of `20'.
Skipping to the precedence check, the current token's left precedence is higher than \qVerb{prec} again, them being `21' for the \qVerb{Star} token and `20' for \qVerb{prec}.
Therefore, \qVerb{infix_expression} is called once again, which calls \qVerb{expression} again, but now during the next precedence check, the left precedence of the following \qVerb{RParen} token, `0', is not higher than the current precedence of `22'.
That means, the innermost \qVerb{expression} call returns with a single `3'.
This `3' is then used as the right-hand side for the multiplicative infix expression.
The same \qVerb{RParen} precedence check fails again for the \qVerb{expression} call with a precedence of `20'.
Thus, the \qVerb{2*3} part together forms the right-hand side of the addition expression.
Once more, the left precedence of \qVerb{RParen}, `0', is not larger than the initial precedence of `0', hence the parser returns to the \qVerb{grouped_expr} call with the entire contents in the parentheses.
Here, the right parenthesis is skipped, and the method returns to the outermost \qVerb{expression} call, assigning the entire grouped expression to \qVerb{lhs}.

In order to understand the right-associativity of the \qVerb{Pow} token, the reader is advised to continue going through this procedure for the rest of the example input.
A curious reader might additionally want to parse the inputs \qVerb{1*2*3}, \qVerb{1**2**3}, and \qVerb{1+(2+3)} by hand.
It should then become clear how Pratt parsing achieves parsing with precedences without them being encoded in the Grammar, and with that, the node types.

\subsubsection{Parser Generators}\label{sec:parser_generators}

For most purposes, it is generally not necessary to implement parsers, and with that, lexers, manually.
Instead, there are so-called \emph{parser generators} that generate parsers based on some specification of the desired syntax and the required precedences.
Often, parser generators define a domain specific grammar notation for the syntax specification, although some parser generators also accept pre-existing grammar notations as input.
% As previously discussed, implementing table-driven parsers, like the shift-reduce LR parsers, is way too error-prone to be done by hand.
% But because of the flexibility and greater language support they bring over LL parsers, it is still preferable to use such a parser for production ready languages.
Most parser generators target some variation of \emph{table-driven} LR parsers.
Table-driven parsers use a table, mapping all possible combinations of tokens on the parse stack and lookahead tokens to an action.
For shift-reduce parsers, the possible actions are shifting, that is, reading the next input token and pushing it to the stack, and reducing, which pops some number of elements from the stack and in place pushes a node to it.
The input syntax must therefore either be unambiguous or augmented by precedence rules, so that a complete parser table can be generated.
\TODO{cite}
\TODO{mention `nom'}
